#!/usr/bin/env python3  
# -*- coding: utf-8 -*-
"""
å®Œæ•´æµç¨‹ï¼šæŠ€æœ¯æŒ‡æ ‡æ‰«æ + AIæ·±åº¦åˆ†æ
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
from datetime import datetime
from src.analyzer import GeminiAnalyzer
import logging

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


def load_scan_results(csv_file):
    """åŠ è½½æ‰«æç»“æœCSV"""
    try:
        df = pd.read_csv(csv_file)
        logger.info(f"âœ… åŠ è½½æ‰«æç»“æœ: {len(df)} åªè‚¡ç¥¨")
        return df
    except Exception as e:
        logger.error(f"âŒ åŠ è½½CSVå¤±è´¥: {e}")
        return None


def convert_to_analyze_context(row):
    """å°†æ‰«æç»“æœè½¬æ¢ä¸ºAI analyzeræœŸæœ›çš„contextæ ¼å¼"""
    
    code = str(row['code'])
    
    # æ„å»ºcontextå­—å…¸
    context = {
        'code': code,
        'stock_name': row.get('name', f'è‚¡ç¥¨{code}'),
        'date': datetime.now().strftime('%Y-%m-%d'),
        
        # ä»Šæ—¥è¡Œæƒ…æ•°æ®
        'today': {
            'close': row.get('close'),
            'open': row.get('open'),
            'high': row.get('high'),
            'low': row.get('low'),
            'pct_chg': row.get('change_pct'),
            'volume': row.get('volume'),
            'amount': row.get('turnover'),
            'ma5': row.get('ma5'),
            'ma10': row.get('ma10'),
            'ma20': row.get('ma20'),
        },
        
        # å®æ—¶æ•°æ®
        'realtime': {
            'price': row.get('close'),
            'volume_ratio': row.get('volume_ratio'),
            'name': row.get('name'),
        },
        
        # å‡çº¿çŠ¶æ€
        'ma_status': 'å¤šå¤´æ’åˆ—' if (row.get('ma5', 0) > row.get('ma10', 0) > row.get('ma20', 0)) else 'å…¶ä»–',
    }
    
    return context


def analyze_scanned_stocks(csv_file, top_n=5):
    """å¯¹æ‰«æç»“æœè¿›è¡ŒAIæ·±åº¦åˆ†æ"""
    
    logger.info("="*70)
    logger.info("ğŸš€ å®Œæ•´åˆ†ææµç¨‹ï¼šæŠ€æœ¯æ‰«æ + AIæ·±åº¦åˆ†æ")
    logger.info("="*70)
    
    # 1. åŠ è½½æ‰«æç»“æœ
    df = load_scan_results(csv_file)
    if df is None or len(df) == 0:
        logger.error("âŒ æ²¡æœ‰å¯åˆ†æçš„è‚¡ç¥¨")
        return
    
    # 2. æŒ‰è¯„åˆ†æ’åºå¹¶å–TOP N
    df_sorted = df.sort_values('six_dim_score', ascending=False)
    top_stocks = df_sorted.head(top_n)
    
    logger.info(f"\nğŸ“Š å°†åˆ†æTOP {len(top_stocks)} åªé«˜åˆ†è‚¡ç¥¨\n")
    
    # 3. åˆå§‹åŒ–AIåˆ†æå™¨
    try:
        analyzer = GeminiAnalyzer()
        if not analyzer.is_available():
            logger.error("âŒ AIåˆ†æå™¨ä¸å¯ç”¨")
            logger.info("ğŸ’¡ è¯·åœ¨.envä¸­é…ç½®AI API:")
            logger.info("   OPENAI_API_KEY=sk-xxx")
            logger.info("   OPENAI_BASE_URL=https://api.deepseek.com/v1")
            return
        logger.info("âœ… AIåˆ†æå™¨å°±ç»ª\n")
    except Exception as e:
        logger.error(f"âŒ AIåˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # 4. é€ä¸€è¿›è¡ŒAIåˆ†æ
    results = []
    for i, (_, row) in enumerate(top_stocks.iterrows(), 1):
        code = str(row['code'])
        name = row.get('name', f'è‚¡ç¥¨{code}')
        score = row.get('six_dim_score', 0)
        
        logger.info(f"ğŸ“Š [{i}/{len(top_stocks)}] åˆ†æ {name} ({code}) - å…­ç»´è¯„åˆ†: {score}/10")
        
        try:
            # è½¬æ¢ä¸ºAIæœŸå¾…çš„æ ¼å¼
            context = convert_to_analyze_context(row)
            
            # AIåˆ†æ
            logger.info(f"  ğŸ¤– è°ƒç”¨AIåˆ†æ...")
            analysis = analyzer.analyze(context, news_context=None)
            
            logger.info(f"  âœ… AIåˆ†æå®Œæˆ")
            logger.info(f"     AIè¯„åˆ†: {analysis.sentiment_score}/100")
            logger.info(f"     è¶‹åŠ¿: {analysis.trend_prediction}")
            logger.info(f"     å»ºè®®: {analysis.operation_advice}")
            
            if analysis.dashboard:
                core = analysis.dashboard.get('core_conclusion', {})
                logger.info(f"     ç»“è®º: {core.get('one_sentence', 'N/A')[:60]}...")
            
            results.append({
                'code': code,
                'name': name,
                'six_dim_score': score,
                'technical_data': row.to_dict(),
                'ai_analysis': analysis
            })
            
        except Exception as e:
            logger.error(f"  âŒ åˆ†æå¤±è´¥: {e}")
        
        print()
    
    # 5. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    if results:
        save_comprehensive_report(results, csv_file)
    
    logger.info("="*70)
    logger.info(f"âœ… åˆ†æå®Œæˆï¼ŒæˆåŠŸåˆ†æ {len(results)}/{top_n} åªè‚¡ç¥¨")
    logger.info("="*70)
    
    return results


def save_comprehensive_report(results, scan_file):
    """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Šï¼ˆæŠ€æœ¯é¢ + AIåˆ†æï¼‰"""
    today = datetime.now().strftime('%Y-%m-%d')
    
    report = f"""# ğŸ“Š ç»¼åˆåˆ†ææŠ¥å‘Š ({today})

> æœ¬æŠ¥å‘Šç»“åˆæŠ€æœ¯æŒ‡æ ‡æ‰«æå’ŒAIæ·±åº¦åˆ†æï¼Œæä¾›å…¨æ–¹ä½çš„æŠ•èµ„å†³ç­–æ”¯æŒ

**æ•°æ®æ¥æº**: `{os.path.basename(scan_file)}`  
**åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M')}  
**AIæ¨¡å‹**: DeepSeek Chat

---

"""
    
    for i, item in enumerate(results, 1):
        analysis = item['ai_analysis']
        tech = item['technical_data']
        
        # è·å–ä»ªè¡¨ç›˜æ•°æ®
        dashboard = analysis.dashboard or {}
        core_conclusion = dashboard.get('core_conclusion', {})
        battle_plan = dashboard.get('battle_plan', {})
        sniper_points = battle_plan.get('sniper_points', {})
        
        report += f"""
## {i}. {item['name']} ({item['code']})

### ğŸ¯ ç»¼åˆè¯„çº§

| ç»´åº¦ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| **æŠ€æœ¯é¢è¯„åˆ†** | **{item['six_dim_score']}/10** | å…­ç»´çœŸå¼ºåŠ¿ç­–ç•¥ |
| **AIæƒ…ç»ªè¯„åˆ†** | **{analysis.sentiment_score}/100** | AIæ·±åº¦åˆ†æ |
| **AIè¶‹åŠ¿é¢„æµ‹** | {analysis.trend_prediction} | - |
| **AIæ“ä½œå»ºè®®** | **{analysis.operation_advice}** | - |
| **ç½®ä¿¡åº¦** | {analysis.confidence_level} | - |

### ğŸ“ˆ æŠ€æœ¯é¢æ•°æ®

- **å½“å‰ä»·æ ¼**: Â¥{tech.get('close', 'N/A')} ({tech.get('change_pct', 'N/A'):+.2f}%)
- **æˆäº¤é¢**: {tech.get('turnover', 0)/1e8:.2f}äº¿
- **é‡æ¯”**: {tech.get('volume_ratio', 'N/A')}x
- **å‡çº¿**: MA5={tech.get('ma5', 'N/A')}, MA10={tech.get('ma10', 'N/A')}, MA20={tech.get('ma20', 'N/A')}
- **æ”¶ç›˜ä½ç½®**: {tech.get('close_position', 'N/A')}%

### ğŸ¤– AIæ ¸å¿ƒç»“è®º

**{core_conclusion.get('one_sentence', 'æš‚æ— ç»“è®º')}**

**ä¿¡å·ç±»å‹**: {core_conclusion.get('signal_type', 'N/A')}  
**æ—¶é—´æ•æ„Ÿåº¦**: {core_conclusion.get('time_sensitivity', 'N/A')}

"""
        
        # æ·»åŠ ç‹™å‡»ç‚¹ä½ï¼ˆå¦‚æœæœ‰ï¼‰
        if sniper_points:
            report += f"""
### ğŸ¯ æ“ä½œç‚¹ä½

- **ç†æƒ³ä¹°å…¥**: {sniper_points.get('ideal_buy', 'N/A')}
- **æ¬¡ä¼˜ä¹°å…¥**: {sniper_points.get('secondary_buy', 'N/A')}
- **æ­¢æŸä½**: {sniper_points.get('stop_loss', 'N/A')}
- **ç›®æ ‡ä½1**: {sniper_points.get('target_1', 'N/A')}
- **ç›®æ ‡ä½2**: {sniper_points.get('target_2', 'N/A')}
"""
        
        # æ·»åŠ æ£€æŸ¥æ¸…å•ï¼ˆå¦‚æœæœ‰ï¼‰
        checklist = battle_plan.get('checklist', {})
        if checklist:
            report += f"""
### âœ… å†³ç­–æ£€æŸ¥æ¸…å•

"""
            for key, value in checklist.items():
                if isinstance(value, dict):
                    status = value.get('status', 'â“')
                    detail = value.get('detail', '')
                    report += f"- {status} **{key}**: {detail}\n"
        
        report += "\n---\n"
    
    # ä¿å­˜æŠ¥å‘Š
    filename = f'data/comprehensive_analysis_{today}.md'
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(report)
    
    logger.info(f"ğŸ“„ ç»¼åˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜: {filename}")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='å¯¹æŠ€æœ¯æ‰«æç»“æœè¿›è¡ŒAIæ·±åº¦åˆ†æ')
    parser.add_argument('--csv', default='data/six_dimension_scan_2026-02-05.csv',
                       help='æ‰«æç»“æœCSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--top', type=int, default=5,
                       help='åˆ†æTOP Nåªè‚¡ç¥¨')
    
    args = parser.parse_args()
    
    analyze_scanned_stocks(args.csv, args.top)


if __name__ == "__main__":
    main()
