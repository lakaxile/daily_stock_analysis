#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥æŠ¥å‘Šå½’æ¡£ç”Ÿæˆå™¨
æ•´åˆæ‰€æœ‰åˆ†æžæŠ¥å‘Šï¼ŒæŒ‰æ—¥æœŸå½’æ¡£
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import shutil
from datetime import datetime
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


class DailyReportArchiver:
    """æ¯æ—¥æŠ¥å‘Šå½’æ¡£å™¨"""
    
    def __init__(self, date_str: str = None):
        """
        åˆå§‹åŒ–å½’æ¡£å™¨
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        """
        self.date = date_str or datetime.now().strftime('%Y-%m-%d')
        self.reports_dir = Path('reports')
        self.archive_dir = self.reports_dir / self.date
        self.data_dir = Path('data')
        
    def create_archive_structure(self):
        """åˆ›å»ºå½’æ¡£ç›®å½•ç»“æž„"""
        # åˆ›å»ºä¸»ç›®å½•
        self.archive_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        (self.archive_dir / 'csv').mkdir(exist_ok=True)
        (self.archive_dir / 'logs').mkdir(exist_ok=True)
        
        logger.info(f"âœ… åˆ›å»ºå½’æ¡£ç›®å½•: {self.archive_dir}")
    
    def collect_reports(self):
        """æ”¶é›†ä»Šæ—¥ç”Ÿæˆçš„æ‰€æœ‰æŠ¥å‘Š"""
        reports = {}
        
        # æŸ¥æ‰¾ä»Šæ—¥æŠ¥å‘Šæ–‡ä»¶
        report_files = {
            'market_env': f'market_env_{self.date}.txt',
            'strategy_a': f'strategy_report_{self.date}.md',
            'strategy_b': f'oversold_report_{self.date}.md',
            's_tracking': f's_stocks_tracking_{self.date}.md',
            'comprehensive': f'daily_comprehensive_report_{self.date}.md',
        }
        
        csv_files = {
            'strategy_a_csv': f'six_dimension_scan_{self.date}.csv',
            'strategy_b_csv': f'oversold_bounce_scan_{self.date}.csv',
        }
        
        log_files = {
            'strategy_scan_log': 'strategy_scan.log',
            'oversold_scan_log': 'oversold_scan.log',
            's_tracking_log': 's_stocks_tracking.log',
        }
        
        # å¤åˆ¶æŠ¥å‘Šæ–‡ä»¶
        for key, filename in report_files.items():
            src = self.data_dir / filename
            if src.exists():
                dst = self.archive_dir / filename
                shutil.copy2(src, dst)
                reports[key] = dst
                logger.info(f"ðŸ“„ å¤åˆ¶æŠ¥å‘Š: {filename}")
        
        # å¤åˆ¶CSVæ–‡ä»¶
        for key, filename in csv_files.items():
            src = self.data_dir / filename
            if src.exists():
                dst = self.archive_dir / 'csv' / filename
                shutil.copy2(src, dst)
                reports[key] = dst
                logger.info(f"ðŸ“Š å¤åˆ¶æ•°æ®: {filename}")
        
        # å¤åˆ¶æ—¥å¿—æ–‡ä»¶
        for key, filename in log_files.items():
            src = Path(filename)
            if src.exists():
                dst = self.archive_dir / 'logs' / filename
                shutil.copy2(src, dst)
                reports[key] = dst
                logger.info(f"ðŸ“ å¤åˆ¶æ—¥å¿—: {filename}")
        
        return reports
    
    def generate_daily_summary(self, reports: dict):
        """ç”Ÿæˆæ¯æ—¥ç»¼åˆæŠ¥å‘Š"""
        
        # è¯»å–å¸‚åœºçŽ¯å¢ƒ
        market_env = ""
        if 'market_env' in reports:
            with open(reports['market_env'], 'r', encoding='utf-8') as f:
                market_env = f.read()
        
        # ç»Ÿè®¡æ•°æ®
        import pandas as pd
        
        strategy_a_stats = {}
        if 'strategy_a_csv' in reports:
            df_a = pd.read_csv(reports['strategy_a_csv'])
            s_level = df_a[df_a['six_dim_score'] >= 8]
            a_level = df_a[(df_a['six_dim_score'] >= 6) & (df_a['six_dim_score'] < 8)]
            strategy_a_stats = {
                'total': len(df_a),
                's_count': len(s_level),
                'a_count': len(a_level),
                'top_stock': s_level.iloc[0] if len(s_level) > 0 else None
            }
        
        strategy_b_stats = {}
        if 'strategy_b_csv' in reports:
            df_b = pd.read_csv(reports['strategy_b_csv'])
            high_score = df_b[df_b['oversold_score'] >= 7]
            medium_score = df_b[(df_b['oversold_score'] >= 5) & (df_b['oversold_score'] < 7)]
            strategy_b_stats = {
                'total': len(df_b),
                'high_count': len(high_score),
                'medium_count': len(medium_score),
            }
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        summary_lines = [
            f"# ðŸ“Š æ¯æ—¥è‚¡ç¥¨åˆ†æžç»¼åˆæŠ¥å‘Š",
            "",
            f"**æ—¥æœŸ**: {self.date}",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "---",
            "",
            "## ðŸ“ æŠ¥å‘Šæ–‡ä»¶ç´¢å¼•",
            "",
            "### ä¸»è¦æŠ¥å‘Š",
            "",
        ]
        
        # æ·»åŠ æ–‡ä»¶ç´¢å¼•
        if 'market_env' in reports:
            summary_lines.append(f"- [å¤§ç›˜çŽ¯å¢ƒåˆ†æž]({reports['market_env'].name})")
        if 'strategy_a' in reports:
            summary_lines.append(f"- [ç­–ç•¥Aï¼šå…­ç»´çœŸå¼ºåŠ¿æ‰«ææŠ¥å‘Š]({reports['strategy_a'].name})")
        if 'strategy_b' in reports:
            summary_lines.append(f"- [ç­–ç•¥Bï¼šé»„é‡‘å‘åå¼¹æ‰«ææŠ¥å‘Š]({reports['strategy_b'].name})")
        if 's_tracking' in reports:
            summary_lines.append(f"- [Sçº§è‚¡ç¥¨è·Ÿè¸ªåˆ†æž]({reports['s_tracking'].name})")
        if 'comprehensive' in reports:
            summary_lines.append(f"- [æ¯æ—¥ç»¼åˆåˆ†æžæŠ¥å‘Š]({reports['comprehensive'].name})")
        
        summary_lines.extend([
            "",
            "### æ•°æ®æ–‡ä»¶",
            "",
        ])
        
        if 'strategy_a_csv' in reports:
            summary_lines.append(f"- [ç­–ç•¥Aæ‰«ææ•°æ®CSV](csv/{reports['strategy_a_csv'].name})")
        if 'strategy_b_csv' in reports:
            summary_lines.append(f"- [ç­–ç•¥Bæ‰«ææ•°æ®CSV](csv/{reports['strategy_b_csv'].name})")
        
        summary_lines.extend([
            "",
            "---",
            "",
            "## ðŸŒ å¸‚åœºçŽ¯å¢ƒæ¦‚è§ˆ",
            "",
        ])
        
        # æ·»åŠ å¸‚åœºçŽ¯å¢ƒæ‘˜è¦
        if market_env:
            env_lines = market_env.split('\n')
            for line in env_lines[2:25]:  # å–å‰é¢çš„å…³é”®ä¿¡æ¯
                summary_lines.append(line)
        
        summary_lines.extend([
            "",
            "---",
            "",
            "## ðŸ“Š æ‰«æç»“æžœæ±‡æ€»",
            "",
        ])
        
        # ç­–ç•¥Aç»Ÿè®¡
        if strategy_a_stats:
            summary_lines.extend([
                "### âš”ï¸ ç­–ç•¥Aï¼šå…­ç»´çœŸå¼ºåŠ¿",
                "",
                f"- **æ‰«æç»“æžœ**: {strategy_a_stats['total']} åª (Açº§ä»¥ä¸Š)",
                f"- ðŸ† **Sçº§** (8-10åˆ†): **{strategy_a_stats['s_count']} åª**",
                f"- ðŸ“ˆ **Açº§** (6-7åˆ†): {strategy_a_stats['a_count']} åª",
                "",
            ])
            
            if strategy_a_stats['top_stock'] is not None:
                top = strategy_a_stats['top_stock']
                summary_lines.extend([
                    "**Top 1 è‚¡ç¥¨**:",
                    f"- {top['name']}({top['code']}) - {int(top['six_dim_score'])}/10åˆ†",
                    f"- æ¶¨å¹…: {top['change_pct']:+.2f}% | ä»·æ ¼: Â¥{top['close']:.2f}",
                    f"- æˆäº¤é¢: {top['turnover']/100000000:.2f}äº¿",
                    "",
                ])
        
        # ç­–ç•¥Bç»Ÿè®¡
        if strategy_b_stats:
            summary_lines.extend([
                "### ðŸ›¡ï¸ ç­–ç•¥Bï¼šé»„é‡‘å‘åå¼¹",
                "",
                f"- **æ‰«æç»“æžœ**: {strategy_b_stats['total']} åª (5åˆ†ä»¥ä¸Š)",
                f"- ðŸ† **é«˜åˆ†è¶…è·Œ** (7-10åˆ†): {strategy_b_stats['high_count']} åª",
                f"- ðŸ“ˆ **ä¸­åº¦è¶…è·Œ** (5-6åˆ†): {strategy_b_stats['medium_count']} åª",
                "",
            ])
        
        summary_lines.extend([
            "---",
            "",
            "## ðŸ’¡ ç­–ç•¥å»ºè®®",
            "",
            "### å¸‚åœºçŽ¯å¢ƒï¼šðŸŸ¢ ç»¿ç¯ (10/10åˆ†)",
            "",
            "**ä¸»åŠ›ç­–ç•¥**: ç­–ç•¥A - å…­ç»´çœŸå¼ºåŠ¿ï¼ˆè¿½æ¶¨ä¸»å‡æµªï¼‰",
            "- **å»ºè®®ä»“ä½**: 60-80%",
            f"- **æŽ¨èè‚¡ç¥¨**: {strategy_a_stats.get('s_count', 0)} åªSçº§è‚¡ç¥¨",
            "",
            "**è¾…åŠ©ç­–ç•¥**: ç­–ç•¥B - é»„é‡‘å‘åå¼¹ï¼ˆè¶…è·Œåå¼¹ï¼‰",
            "- **å»ºè®®ä»“ä½**: 10-20%",
            f"- **å…³æ³¨è‚¡ç¥¨**: {strategy_b_stats.get('medium_count', 0)} åªä¸­åº¦è¶…è·Œè‚¡",
            "",
            "---",
            "",
            "## ðŸ›¡ï¸ é£ŽæŽ§æç¤º",
            "",
            "1. **æ­¢æŸçºªå¾‹**: ç­–ç•¥Aè·Œç ´MA5æ­¢æŸï¼Œç­–ç•¥Bè·Œç ´å‰ä½Žæˆ–-5%æ­¢æŸ",
            "2. **ä»“ä½ç®¡ç†**: æ€»ä»“ä½ä¸è¶…è¿‡90%ï¼Œä¿ç•™10%çŽ°é‡‘",
            "3. **åˆ†æ•£æŠ•èµ„**: å•åªè‚¡ç¥¨â‰¤20%ï¼Œé¿å…è¿‡åº¦é›†ä¸­",
            "4. **åŠ¨æ€è°ƒæ•´**: å¯†åˆ‡å…³æ³¨å¤§ç›˜çŽ¯å¢ƒå˜åŒ–ï¼ŒåŠæ—¶è°ƒæ•´ç­–ç•¥",
            "",
            "---",
            "",
            f"**æ•°æ®æ¥æº**: yfinance API",
            f"**æŠ¥å‘Šç”Ÿæˆ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**å½’æ¡£è·¯å¾„**: {self.archive_dir}",
        ])
        
        summary = "\n".join(summary_lines)
        
        # ä¿å­˜ç»¼åˆæŠ¥å‘Š
        summary_file = self.archive_dir / 'DAILY_SUMMARY.md'
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(summary)
        
        logger.info(f"âœ… ç”Ÿæˆæ¯æ—¥æ‘˜è¦: {summary_file.name}")
        
        return summary_file
    
    def update_index(self):
        """æ›´æ–°æŠ¥å‘Šç´¢å¼•"""
        index_file = self.reports_dir / 'INDEX.md'
        
        # è¯»å–çŽ°æœ‰ç´¢å¼•
        existing_entries = []
        if index_file.exists():
            with open(index_file, 'r', encoding='utf-8') as f:
                content = f.read()
                # æå–è¡¨æ ¼è¡Œ
                for line in content.split('\n'):
                    if line.startswith('|') and not line.startswith('| æ—¥æœŸ'):
                        existing_entries.append(line)
        
        # åˆ›å»ºæ–°æ¡ç›®
        new_entry = f"| {self.date} | [æŸ¥çœ‹æŠ¥å‘Š]({self.date}/DAILY_SUMMARY.md) | ç­–ç•¥A: 50åªSçº§, ç­–ç•¥B: 22åªä¸­åº¦è¶…è·Œ | ðŸŸ¢ ç»¿ç¯ |"
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if not any(self.date in entry for entry in existing_entries):
            existing_entries.insert(0, new_entry)  # æœ€æ–°çš„åœ¨å‰é¢
        
        # ç”Ÿæˆç´¢å¼•
        index_lines = [
            "# ðŸ“Š æ¯æ—¥è‚¡ç¥¨åˆ†æžæŠ¥å‘Šç´¢å¼•",
            "",
            "æŒ‰æ—¥æœŸå½’æ¡£çš„æ‰€æœ‰è‚¡ç¥¨åˆ†æžæŠ¥å‘Šã€‚",
            "",
            "---",
            "",
            "## æŠ¥å‘Šåˆ—è¡¨",
            "",
            "| æ—¥æœŸ | æŠ¥å‘Šé“¾æŽ¥ | æ‘˜è¦ | å¸‚åœºçŽ¯å¢ƒ |",
            "|------|---------|------|---------|",
        ]
        
        index_lines.extend(existing_entries)
        
        index_lines.extend([
            "",
            "---",
            "",
            "## ä½¿ç”¨è¯´æ˜Ž",
            "",
            "1. ç‚¹å‡»**æŠ¥å‘Šé“¾æŽ¥**æŸ¥çœ‹å½“æ—¥å®Œæ•´åˆ†æž",
            "2. æ¯æ—¥æŠ¥å‘ŠåŒ…å«ï¼šå¤§ç›˜çŽ¯å¢ƒã€ç­–ç•¥Aæ‰«æã€ç­–ç•¥Bæ‰«æã€Sçº§è‚¡ç¥¨è·Ÿè¸ª",
            "3. CSVæ•°æ®æ–‡ä»¶ä½äºŽå„æ—¥æœŸç›®å½•çš„ `csv/` å­ç›®å½•",
            "4. æ—¥å¿—æ–‡ä»¶ä½äºŽå„æ—¥æœŸç›®å½•çš„ `logs/` å­ç›®å½•",
            "",
            "---",
            "",
            f"**æœ€åŽæ›´æ–°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        ])
        
        index_content = "\n".join(index_lines)
        
        with open(index_file, 'w', encoding='utf-8') as f:
            f.write(index_content)
        
        logger.info(f"âœ… æ›´æ–°ç´¢å¼•æ–‡ä»¶: {index_file}")
        
        return index_file
    
    def archive(self):
        """æ‰§è¡Œå®Œæ•´çš„å½’æ¡£æµç¨‹"""
        logger.info("=" * 70)
        logger.info(f"ðŸ“¦ å¼€å§‹å½’æ¡£ {self.date} çš„åˆ†æžæŠ¥å‘Š")
        logger.info("=" * 70)
        
        # åˆ›å»ºç›®å½•ç»“æž„
        self.create_archive_structure()
        
        # æ”¶é›†æŠ¥å‘Š
        logger.info("\nðŸ“„ æ”¶é›†æŠ¥å‘Šæ–‡ä»¶...")
        reports = self.collect_reports()
        
        if not reports:
            logger.warning("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•æŠ¥å‘Šæ–‡ä»¶")
            return None
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        logger.info("\nðŸ“ ç”Ÿæˆæ¯æ—¥æ‘˜è¦...")
        summary_file = self.generate_daily_summary(reports)
        
        # æ›´æ–°ç´¢å¼•
        logger.info("\nðŸ“š æ›´æ–°æŠ¥å‘Šç´¢å¼•...")
        index_file = self.update_index()
        
        logger.info("\n" + "=" * 70)
        logger.info("âœ… å½’æ¡£å®Œæˆï¼")
        logger.info("=" * 70)
        logger.info(f"ðŸ“ å½’æ¡£ç›®å½•: {self.archive_dir}")
        logger.info(f"ðŸ“„ æ¯æ—¥æ‘˜è¦: {summary_file}")
        logger.info(f"ðŸ“š ç´¢å¼•æ–‡ä»¶: {index_file}")
        logger.info(f"ðŸ“Š æŠ¥å‘Šæ•°é‡: {len(reports)}")
        logger.info("=" * 70)
        
        return {
            'archive_dir': self.archive_dir,
            'summary_file': summary_file,
            'index_file': index_file,
            'reports': reports,
        }


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='æ¯æ—¥æŠ¥å‘Šå½’æ¡£ç”Ÿæˆå™¨')
    parser.add_argument('--date', help='æ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºä»Šå¤©')
    
    args = parser.parse_args()
    
    archiver = DailyReportArchiver(date_str=args.date)
    result = archiver.archive()
    
    return result


if __name__ == "__main__":
    main()
